{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datapipe.datatable import DataStore, DBConn\n",
    "from datapipe.compute import Catalog, Pipeline, Table, run_pipeline\n",
    "from datapipe.store.database import TableStoreDB\n",
    "from datapipe.store.redis import RedisStore\n",
    "from datapipe.core_steps import BatchTransform, UpdateExternalTable\n",
    "from datapipe.types import data_to_index\n",
    "from sqlalchemy.engine import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import Column, String, JSON, Integer, Boolean\n",
    "import pandas as pd\n",
    "import redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entities:\n",
    "# DBConn - database connection (conn url string or conn object itself. question - does dbconn only eat sqlalchemy?)\n",
    "# DataStore - metatables data storage (entity where hashes and info about changes is stored)\n",
    "# Table - data table (could be in db, or in file? question - are all sources of data described as Table?)\n",
    "# Catalog - entity that describes DataTables\n",
    "# Store - entity with methods for different kinds of storage.  could be TableStoreDB, TableDataSingleFileStore, folder etc...\n",
    "# TableStoreDB - table data stored in database.\n",
    "# Table schemas described in sqlaclchemy terms and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "DBCONN = \"postgresql://postgres:testpass@localhost:5432/test\"\n",
    "engine = create_engine(DBCONN)\n",
    "# two separate connections needed for datastore and main tables\n",
    "engine.execute('''\n",
    "DROP SCHEMA public CASCADE;\n",
    "CREATE SCHEMA public;''')\n",
    "dbconn = DBConn(DBCONN)\n",
    "meta_dbconn = DBConn(DBCONN)\n",
    "ds = DataStore(meta_dbconn)\n",
    "redis_conn_mid = redis.Redis(decode_responses=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine.execute(\n",
    "#     \"\"\"\n",
    "#     drop table if exists pipeline_start_meta;\n",
    "#     drop table if exists pipeline_end_meta;\n",
    "#     drop table if exists test_output;\n",
    "#     \"\"\"\n",
    "# )\n",
    "# keys = redis_conn.keys()\n",
    "# if keys:\n",
    "#     redis_conn.delete(*keys)\n",
    "\n",
    "# INPUT_SCHEMA = [\n",
    "#     Column(\"user_id\", String, primary_key=True),\n",
    "#     Column(\"click_count\", Integer)\n",
    "# ]\n",
    "\n",
    "# OUTPUT_SCHEMA = [\n",
    "#     Column(\"user_id\", String, primary_key=True),\n",
    "#     Column(\"click_count\", Integer),\n",
    "#     Column(\"click_count_doubled\", Integer)\n",
    "# ]\n",
    "\n",
    "# catalog = Catalog({\n",
    "#     \"pipeline_start\": Table(store=RedisStore(redis_conn, \"test_input\", INPUT_SCHEMA)),\n",
    "#     \"pipeline_end\": Table(store=TableStoreDB(dbconn, \"test_output\", OUTPUT_SCHEMA))\n",
    "# })\n",
    "\n",
    "# def double(df):\n",
    "#     df['click_count_doubled'] = df['click_count'] * 2\n",
    "#     return df\n",
    "\n",
    "# pipeline = Pipeline([\n",
    "#     UpdateExternalTable('pipeline_start'),\n",
    "#     BatchTransform(\n",
    "#         double,\n",
    "#         inputs=[\"pipeline_start\"],\n",
    "#         outputs=[\"pipeline_end\"],\n",
    "#     )\n",
    "# ])\n",
    "\n",
    "# run_pipeline(ds, catalog, pipeline)\n",
    "# input_dt = catalog.get_datatable(ds, \"pipeline_start\")\n",
    "# output_dt = catalog.get_datatable(ds, \"pipeline_end\")\n",
    "# print(input_dt.get_data())\n",
    "# print(output_dt.get_data())\n",
    "\n",
    "# redis_conn.set('a', 1)\n",
    "# run_pipeline(ds, catalog, pipeline)\n",
    "# print(input_dt.get_data())\n",
    "# print(output_dt.get_data())\n",
    "\n",
    "# redis_conn.delete('a')\n",
    "# run_pipeline(ds, catalog, pipeline)\n",
    "# print(input_dt.get_data())\n",
    "# print(output_dt.get_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MID PIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SCHEMA = [\n",
    "    Column(\"user_id\", String, primary_key=True),\n",
    "    Column(\"click_count\", Integer)\n",
    "]\n",
    "\n",
    "INTERM_SCHEMA = [\n",
    "    Column('user_id', String, primary_key=True),\n",
    "    Column('click_count_doubled', Integer)\n",
    "]\n",
    "\n",
    "OUTPUT_SCHEMA = [\n",
    "    Column(\"user_id\", String, primary_key=True),\n",
    "    Column(\"click_count_doubled\", Integer),\n",
    "    Column(\"click_count_doubled_squared\", Integer)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Catalog({\n",
    "    \"pipeline_start\": Table(store=TableStoreDB(dbconn, \"test_input\", INPUT_SCHEMA)),\n",
    "    \"pipeline_mid\": Table(store=RedisStore(redis_conn_mid, INTERM_SCHEMA)),\n",
    "    \"pipeline_end\": Table(store=TableStoreDB(dbconn, \"test_output\", OUTPUT_SCHEMA))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double(df):\n",
    "    df['click_count_doubled'] = df['click_count'] * 2\n",
    "    df.drop(columns=['click_count'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def double_and_square(df):\n",
    "    df['click_count_doubled_squared'] = df['click_count_doubled']**2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    UpdateExternalTable('pipeline_start'),\n",
    "    BatchTransform(\n",
    "        double,\n",
    "        inputs=[\"pipeline_start\"],\n",
    "        outputs=[\"pipeline_mid\"],\n",
    "    ),\n",
    "    BatchTransform(\n",
    "        double_and_square,\n",
    "        inputs=['pipeline_mid'],\n",
    "        outputs=['pipeline_end']\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 23.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [user_id, click_count]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [user_id, click_count_doubled, click_count_doubled_squared]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_pipeline(ds, catalog, pipeline)\n",
    "input_dt = catalog.get_datatable(ds, \"pipeline_start\")\n",
    "output_dt = catalog.get_datatable(ds, \"pipeline_end\")\n",
    "print(input_dt.get_data())\n",
    "print(output_dt.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id  click_count_doubled\n",
      "0     abc                  246\n",
      "  user_id  click_count\n",
      "0     abc          123\n",
      "  user_id  click_count_doubled  click_count_doubled_squared\n",
      "0     abc                  246                        60516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "engine.execute('''\n",
    "insert into test_input values ('abc', 123)\n",
    "''')\n",
    "run_pipeline(ds, catalog, pipeline)\n",
    "input_dt = catalog.get_datatable(ds, \"pipeline_start\")\n",
    "mid_dt = catalog.get_datatable(ds, 'pipeline_mid')\n",
    "output_dt = catalog.get_datatable(ds, \"pipeline_end\")\n",
    "print(input_dt.get_data())\n",
    "print(mid_dt.get_data())\n",
    "print(output_dt.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [user_id, click_count_doubled]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [user_id, click_count]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [user_id, click_count_doubled, click_count_doubled_squared]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "engine.execute('''\n",
    "delete from test_input where user_id = 'abc'\n",
    "''')\n",
    "run_pipeline(ds, catalog, pipeline)\n",
    "input_dt = catalog.get_datatable(ds, \"pipeline_start\")\n",
    "mid_dt = catalog.get_datatable(ds, 'pipeline_mid')\n",
    "output_dt = catalog.get_datatable(ds, \"pipeline_end\")\n",
    "print(input_dt.get_data())\n",
    "print(mid_dt.get_data())\n",
    "print(output_dt.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d39f20ce00aaf38ea377c8d0bf80d1ffd1fae8bb8a33e458e99c5fd845ceed94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
